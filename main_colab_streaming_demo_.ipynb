{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63d6a1f",
   "metadata": {},
   "source": [
    "# üà∫ Real-Time Japanese-English S2ST (Phase 2)\n",
    "Streaming ASR ‚Üí Incremental NMT ‚Üí Streaming TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e03df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from asr.streaming_whisper_asr import StreamingWhisperASR\n",
    "from nmt.incremental_mt5_translation import IncrementalMT5Translator\n",
    "from tts.streaming_tts import StreamingTTS\n",
    "from utils.audio_io import AudioStreamHandler, play_audio\n",
    "from utils.japanese_utils import tokenize_japanese, detect_honorific\n",
    "import time, tempfile, soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ASR, NMT, TTS\n",
    "asr = StreamingWhisperASR(model_size=\"medium\")\n",
    "translator = IncrementalMT5Translator()\n",
    "tts = StreamingTTS()\n",
    "audio_handler = AudioStreamHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72eea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time streaming loop\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "\n",
    "@contextmanager\n",
    "def mic_stream():\n",
    "    stream = audio_handler.start_input_stream()\n",
    "    stream.start()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "\n",
    "print(\"üéôÔ∏è Speak in Japanese ‚Äî Streaming will begin...\")\n",
    "\n",
    "results = []\n",
    "with mic_stream():\n",
    "    for _ in range(5):  # process 5 chunks (~1.5 seconds total)\n",
    "        audio_chunk = audio_handler.get_audio_chunk().flatten()\n",
    "        audio_chunk_fp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n",
    "        sf.write(audio_chunk_fp, audio_chunk, audio_handler.samplerate)\n",
    "\n",
    "        start_time = time.time()\n",
    "        jp_texts = asr.stream_transcribe(audio_chunk_fp)\n",
    "        jp_text = \" \".join(jp_texts)\n",
    "        print(\"üìù JP:\", jp_text)\n",
    "\n",
    "        # Honorific register detection\n",
    "        register = detect_honorific(jp_text)\n",
    "        print(\"üìõ Register:\", register)\n",
    "\n",
    "        # Translate\n",
    "        en_text = translator.translate_incremental(jp_text)\n",
    "        print(\"üåê EN:\", en_text)\n",
    "\n",
    "        # TTS\n",
    "        out_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n",
    "        tts.stream_synthesize(en_text, out_path)\n",
    "        play_audio(out_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        latency = round((end_time - start_time) * 1000, 2)\n",
    "        print(f\"‚ö° Latency: {latency} ms\\n\")\n",
    "        results.append({\n",
    "            \"jp\": jp_text, \"en\": en_text, \"latency_ms\": latency, \"register\": register\n",
    "        })\n",
    "\n",
    "print(\"‚úÖ Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09580e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚è±Ô∏è Metrics Summary\n",
    "from statistics import mean\n",
    "latencies = [r['latency_ms'] for r in results]\n",
    "print(f\"üîÅ Average Latency: {mean(latencies):.2f} ms\")\n",
    "print(\"Translation Outputs:\")\n",
    "for r in results:\n",
    "    print(f\"üà∂ JP: {r['jp']} ‚Üí üó£ EN: {r['en']} ({r['latency_ms']} ms)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Translation Metric Evaluation ‚Äî Add Ref/Hyp Pairs if Available\n",
    "# from evaluate import load\n",
    "# metric = load(\"bleu\")\n",
    "# ref = [\"Hello everyone\"]\n",
    "# hyp = [\"Hi all\"]\n",
    "# results = metric.compute(predictions=hyp, references=[[r] for r in ref])\n",
    "# print(\"BLEU:\", results['bleu'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc93ba",
   "metadata": {},
   "source": [
    "## üîÑ Future: Direct S2ST with Translatotron 2\n",
    "- ESPnet or Google Research repo\n",
    "- Requires pre-trained speech-to-speech model\n",
    "- Integration work planned for Phase 3\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
